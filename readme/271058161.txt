Note: an improved version is come online, with references to a paper under review, as soon as we receive the submission feedback.
This repository mirrors the Monocular Camera Calibration for Autonomous Driving â€” a comparative study paper, which summarizes the main camera models used for perspective cameras (narrow and wide-angle), and fisheye cameras, describing the various distortion parameters involved. It demonstrates the calibration of a wide-angle camera setup and a fisheye lens setup, comparing the use of various distortion models. Furthermore, it describes the use of homography for perspective transformations between a camera view and a virtual camera view. The main goal of this demo is to provide, together with the cited document, an overview on monocular camera calibration and bids-eye view perspective transformation, serving as a starting point for researchers starting to work with monocular vision, paricularly for autonomous driving. This repository provides all the algorithms used throughout the document, using a Jupyter notebook and OpenCV 4.1.1, so one can easily experiment and run then without any further installations.
TO GET STARTED, you should open the Calibration&BirdsEyeView file and and go to shown on top.
A camera consists mainly of a planar optical sensor and a lens, together with the electronics needed to obtain thed igital image of the scene projected onto the optical sensor. Camera images exhibit distortion due to the lens characteristics and production defects. The most common distortion effects are the radial distortion, tangential distortion and the thin prism distortion, which affect the captured point coordinates, and can be rectified using calibration algorithms considering, for instance, the following distortion models:
Below you can see some of the results that can be obtained through the application of the calibration results to remove the image distortion.
The homography can be used to relate the transformation between two different camera views, specified on a common reference frame. For autonomous driving, our reference plane is the ground plane, which can be fixed with respect to the vehicle. By placing a planar chessboard in front of the robot and in view of the (previously calibrated) camera, one can use the same techniques to estimate the camera pose with respect to the chessboard on the floor, that is, the extrinsic parameters (or the inverse, the chessboard pose with respect to the camera). That information can later be used to compute a birds-eye-view of the road, considering a virtual camera.
The results above show how important the calibration can be, with further details given in the paper. Computing the birds-eye-view can help improve the results for lane detection and tracking. By providing the Jupyter notebook together with the paper, we hope that others can more easily understand and apply these important concepts, which are ever more present on these camera systems used for autonomous driving.
Standard Model
Rational Model
Thin Prism Model
Tilted Model
Fisheye Model
MonoCamCalib4AD
Conclusions
Calibration algorithm
Homography Results
Wide-angle Lens Example
Fisheye Lens Example
Birds-eye View Example
