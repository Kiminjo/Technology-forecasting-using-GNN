
OpenPCDet is a clear, simple, self-contained open source project for LiDAR-based 3D object detection.
It is also the official code release of [PointRCNN], [Part-A^2 net] and [PV-RCNN].
[2020-11-27] Bugfixed: Please re-prepare the validation infos of Waymo dataset (version 1.2) if you would like to use our provided Waymo evaluation tool (see PR). Note that you do not need to re-prepare the training data and ground-truth database.
[2020-11-10] NEW: The Waymo Open Dataset has been supported with state-of-the-art results. Currently we provide the configs and results of SECOND, PartA2 and PV-RCNN on the Waymo Open Dataset, and more models could be easily supported by modifying their dataset configs.
[2020-08-10] Bugfixed: The provided NuScenes models have been updated to fix the loading bugs. Please redownload it if you need to use the pretrained NuScenes models.
[2020-07-30] OpenPCDet v0.3.0 is released with the following features:
[2020-07-17] Add simple visualization codes and a quick demo to test with custom data.
[2020-06-24] OpenPCDet v0.2.0 is released with pretty new structures to support more models and datasets.
[2020-03-16] OpenPCDet v0.1.0 is released.
Note that we have upgrated PCDet from v0.1 to v0.2 with pretty new structures to support various datasets and models.
OpenPCDet is a general PyTorch-based codebase for 3D object detection from point cloud. It currently supports multiple state-of-the-art 3D object detection methods with highly refactored codes for both one-stage and two-stage 3D detection frameworks.
Based on OpenPCDet toolbox, we win the Waymo Open Dataset challenge in 3D Detection, 3D Tracking, Domain Adaptation three tracks among all LiDAR-only methods, and the Waymo related models will be released to OpenPCDet soon.
We are actively updating this repo currently, and more datasets and models will be supported soon. Contributions are also welcomed.

Unified 3D box definition: (x, y, z, dx, dy, dz, heading).
Flexible and clear model structure to easily support various 3D detection models:


Selected supported methods are shown in the below table. The results are the 3D detection performance of moderate difficulty on the val set of KITTI dataset.
All models are trained with 8 GTX 1080Ti GPUs and are available for download.
We provide the setting of DATA_CONFIG.SAMPLED_INTERVAL on the Waymo Open Dataset (WOD) to subsample partial samples for training and evaluation, so you could also play with WOD by setting a smaller DATA_CONFIG.SAMPLED_INTERVAL even if you only have limited GPU resources.
By default, all models are trained with 20% data (~32k frames) of all the training samples on 8 GTX 1080Ti GPUs, and the results of each cell here are mAP/mAPH calculated by the official Waymo evaluation metrics on the whole validation set (version 1.2).
We could not provide the above pretrained models due to Waymo Dataset License Agreement, but you could easily achieve similar performance by training with the default configs.
More datasets are on the way.
Please refer to INSTALL.md for the installation of OpenPCDet.
Please refer to DEMO.md for a quick demo to test with a pretrained model and visualize the predicted results on your custom data or the original KITTI data.
Please refer to GETTING_STARTED.md to learn more usage about this project.
OpenPCDet is released under the Apache 2.0 license.
OpenPCDet is an open source project for LiDAR-based 3D scene perception that supports multiple LiDAR-based perception models as shown above. Some parts of PCDet are learned from the official released codes of the above supported methods. We would like to thank for their proposed methods and the official implementation.
We hope that this repo could serve as a strong and flexible codebase to benefit the research community by speeding up the process of reimplementing previous works and/or developing new methods.
If you find this project useful in your research, please consider cite:
Welcome to be a member of the OpenPCDet development team by contributing to this repo, and feel free to contact us for any potential contributions.
Changelog
Design Pattern
Model Zoo
Installation
Quick Demo
Getting Started
Citation
The Point-based and Anchor-Free models (PointRCNN, PartA2-Free) are supported now.
The NuScenes dataset is supported with strong baseline results (SECOND-MultiHead (CBGS) and PointPillar-MultiHead).
High efficiency than last version, support PyTorch 1.1~1.7 and spconv 1.0~1.2 simultaneously.
Data-Model separation with unified point cloud coordinate for easily extending to custom datasets:
Unified 3D box definition: (x, y, z, dx, dy, dz, heading).
Flexible and clear model structure to easily support various 3D detection models:
Support various models within one framework as:
Support both one-stage and two-stage 3D object detection frameworks
Support distributed training & testing with multiple GPUs and multiple machines
Support multiple heads on different scales to detect different classes
Support stacked version set abstraction to encode various number of points in different scenes
Support Adaptive Training Sample Selection (ATSS) for target assignment
Support RoI-aware point cloud pooling & RoI-grid point cloud pooling
Support GPU version 3D IoU calculation and rotated NMS
All models are trained with 8 GTX 1080Ti GPUs and are available for download.
The training time is measured with 8 TITAN XP GPUs and PyTorch 1.5.
OpenPCDet
Overview
Changelog
Introduction
Model Zoo
Installation
Quick Demo
Getting Started
License
Acknowledgement
Citation
Contribution
What does OpenPCDet toolbox do?
OpenPCDet design pattern
Currently Supported Features
KITTI 3D Object Detection Baselines
NuScenes 3D Object Detection Baselines
Waymo Open Dataset Baselines
Other datasets
